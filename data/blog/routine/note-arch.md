超浓缩的码农笔记



# 计算机篇





# 后端篇

## Redis



### Redis数据不一致问题

假设当前更新Redis的逻辑是，更新DB => 更新Redis缓存

假如两条线程同时更新DB，线程A的DB设置value=100 => 线程B的DB设置value=200 => 线程B的Redis更新缓存为200 => 线程A的Redis更新缓存为100.

此时正确的最终结果应该是200，但是因为执行的延迟缓存中是100，就产生了不一致的问题

解法就是**Cache Aside Pattern**工作流

读数据：如果缓存命中就返回数据，否则从数据库读取并更新缓存

写数据：先更新数据库，然后手动让此Key的缓存**失效**，即在写的过程中不去更新缓存

这样即使读请求是在AB两个线程执行更新的间隙发生，得到的数据在那个时间点也是合理的，而在两个线程都结束之后就更加没问题了



### 缓存穿透

一般只非正常情况下，比如遭到黑客攻击，用海量的不存在的Key来做查询，这样缓存就无法命中，只能去DB进行查询。一旦DB符合太重，就可能导致系统延迟甚至崩溃

解决问题的初级办法，是把空值也缓存起来，并设置过期时间，这样在短时间内，空值就可以命中缓存返回。但是无法应对不重复的Key

终极解决方法是使用**布隆过滤器**，它可以做到判断一个**Key绝对不在一个集合里或者可能存在一个集合里**

比如基于ID字段建立布隆过滤器，访问先到达过滤器，如果判断**绝对不在集合中**，那就拒绝访问，否则就放行到Redis中，进行过去的操作。从而大大减轻DB的压力

#### 布隆过滤器的原理

假设有一段8bit的内存，每位都可以用0/1存储，初始下所以都是0，比如我的ID是"A"，那么就把A做Hash运算成为一个数字之后与8取模，比如得到数字2，那么就在8位的第二个位置存1。

此时请求到来，就会用同样的方法计算下Key在此内存中的位置，如果这个位置为1就代表**可能**在集合里，否则**必然**不在集合里。

这里说的可能是，总共就8位地址，即使不同数字取模也是可能落在一个位置上的，所以不是百分百有效，但是一旦为0就代表，这个hash值肯定不在集合中

所以为了把这个`可能`的精确度提升，有两种方式

1. 把内存的长度扩大，这样落到同一个位置的可能性就小了
2. 使用不同的hash算法对同一个Key进行计算，比如对一个Key用三种方式计算，这样就会落到三个不同的位置上，那另外一个字符会同时落在相同的三个位置的概率就非常小了
3. 但如果内存用的太多就不划算了，hash算法用太多，过滤的速度肯定也会变慢，所以都不是越大越多越好

综上，布隆过滤器可以做到用少量的内存就预判断一个Key是否在集合中，是一种非常高效的防护手段



### 热点数据失效

当一个热点数据失效，可能会有N条线程同时访问DB要求得到新的数据，此时DB的压力就会变得很大

解决办法就是当进程发现Redis缓存失效 => 通过Redis获取**分布式锁** => 如果拿锁不成功就等待一会儿再尝试看看缓存有没有，如果还是没有那就再尝试拿锁，有数据则返回，如此往复  => 拿锁成功 => 从DB获取数据 => 更新缓存释放分布式锁 => 返回数据

这样不论有多少线程同时请求这条热点数据，都只有一条线程会访问数据库



## 数据库

### 分布式下数据库怎么做读写分离的数据同步？

1. **基于SQL的重放**，就是把在主上执行的insert/update/delete语句在从数据库上再执行一遍。但这有一个问题就是比如update_timestamp还有random函数产生的值会在各个库中不一致
2. **基于行的复制**，通过日志的方式，告诉从数据库，具体发生了什么变化，然后直接复制变化的部分就行。但这里的问题就是比如全表更新一个字段的值，那可能要产生几十万条复制记录。

所以综上，两种方式需要按需混合使用



### 分布式下的数据延迟

即主数据库已经写入，但是还没来得及同步到从数据库，读的请求就发生了。 这就产生了数据不一致的问题。

数据同步只能做到**最终一致性**。如果复制也做成同步ACK，那整个吞吐也会受到影响。

一个简单的策略就是，如果一个数据主键key被更新，那就在缓存里记录一下，并设置一个较短的过期时间，如果读请求命中缓存，那请求就从主DB里读，反之就正常从从DB里读



# 架构篇

## 分布式事务

假设在一个单机里，如果调用一个函数或者进程失败，自然就知道结果，该回滚回滚该commit就commit，所以单机事务比较简单





## 高可用

高可用本质要解决的问题就是**单点失败**的问题。因为任何一个单点都用承载的上限



### Nginx如果做高可用？

通过**Keepalived**的方式，用主从的方式部署多个实例，但是**有且只有一个实例是在工作的**，当主挂了之后，原地待命的从实例就开始接管。在整个过程中ngnix集群只会对外暴露一个IP作为对外的统一入口



### Redis如何做高可用？

1. 使用Redis Cluster
2. 在集群中的每组实例，都只负责一部分的数据存储，比如3组实例就是负责三分之一的数据量
3. 每存储一个key，都可以通过Hash算法得到一个%16384（就是一个数字）的值，看这个值落在哪组实例的区域里面就存在具体哪个实例里面，比如1号实例负责1 ~ 5000， 2号负责5001 ~ 10000
4. 当要取一个key时，可以访问任意节点，判断是不是存在自身，如果不是就转发给对应的实例组来返回
5. 当添加一个新节点，每个原先的节点都会分出一部分数据交给新的实例。相反删除一个节点，也会把这个节点的数据分给活着的节点
6. 最后就是**故障转移**，上面说的每个组，其实都可以是一个集群，每个集群内部有主从关系，实时备份，一旦主挂了，从接上
7. 总结就是前面的6点主要实现，在单机内存有限（比如64G）的情况下，怎么去缓存TB/PB级的数据，最后一步是描述故障转移的实现



### 服务端怎么做高可用？

1. 做到无状态，即**stateless**，这样就可以做无限水平扩展
2. 把类似session等带状态的内容，存储到数据库或者Redis
3. 最重要的是在nginx与服务端转发的层面，要做到**负载均衡**



### 数据库如何做高可用？

在分布式环境下，做到数据的强一致性是很难的

1. 读写分离，master节点可读可写，slave节点只能读，这是根据读多写少这个规律来的，同时读写分离可以减少锁的竞争
2. 主从间实时备份
3. 添加一层代理层，应用层无需知道谁是主谁是从